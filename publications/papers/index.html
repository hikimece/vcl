<!DOCTYPE html>
<html lang="en-us" dir="ltr" class="scroll-smooth" data-default-appearance="dark"
  data-auto-appearance="false"><head>
  <meta charset="utf-8" />
  
  <meta http-equiv="content-language" content="en-us" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  
  <title> &middot; VCL Lab.</title>
  <meta name="title" content=" &middot; VCL Lab." />
  
  
  
  
  
  <link rel="canonical" href="https://hikimece.github.io/vcl/publications/papers/" />
  
  <link rel="alternate" type="application/rss+xml" href="/vcl/publications/papers/index.xml" title="VCL Lab." />
  
  
  
  
  
  
  
  
  
  
  
  
  <link type="text/css" rel="stylesheet" href="/vcl/css/main.bundle.min.4c19904eea2898fc46b06fa5c55009ba1363d064960033f0f897529aa3fa8f0d92bd1677f3ba3998bdbae7703134f05b448c3708f2babb64da07c1798ef92dc2.css"
    integrity="sha512-TBmQTuoomPxGsG&#43;lxVAJuhNj0GSWADPw&#43;JdSmqP6jw2SvRZ387o5mL2653AxNPBbRIw3CPK6u2TaB8F5jvktwg==" />
  
  
  <script type="text/javascript" src="/vcl/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js"
    integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj&#43;e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script>
  
  
  
  
  
  
  
  
  
  
  
  <script defer type="text/javascript" id="script-bundle" src="/vcl/js/main.bundle.min.c178288131a2f1ad46910438db47ac5f7e1c48cf949e49f6dc3310c8ec9660e23fe505805eba4e2e73711335808500360d773a2b64322feb35df52856edca286.js"
    integrity="sha512-wXgogTGi8a1GkQQ420esX34cSM&#43;Unkn23DMQyOyWYOI/5QWAXrpOLnNxEzWAhQA2DXc6K2QyL&#43;s131KFbtyihg==" data-copy="" data-copied=""></script>
  
  
  
  <script src="/vcl/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js" integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S&#43;Yti0U7QtuZvQ=="></script>
  
  
  
  <link rel="apple-touch-icon" sizes="180x180" href="/vcl/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/vcl/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/vcl/favicon-16x16.png" />
  <link rel="manifest" href="/vcl/site.webmanifest" />
  
  
  
  
  
  
  
  
  <meta property="og:url" content="https://hikimece.github.io/vcl/publications/papers/">
  <meta property="og:site_name" content="VCL Lab.">
  <meta property="og:title" content="VCL Lab.">
  <meta property="og:description" content="International Publications # Minsu Kim, Hyung-Il Kim, and Yong Man Ro, &#34;Prompt Tuning of Deep Neural Networks for Speaker-Adaptive Visual Speech Recognition,&#34; IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), vol. 47, no. 2, pp. 1042-1055, 2025. [Paper] Sangmin Lee, Hyung-Il Kim, and Yong Man Ro, &#34;Text-Guided Distillation Learning to Diversify Video Embeddings for Text-Video Retrieval,&#34; Pattern Recognition (PR), vol. 156, pp. 110754, 2024. [Paper] Youngmin Oh, Hyung-Il Kim, Seong Tae Kim, and Jung Uk Kim, &#34;MonoWAD: Weather-Adaptive Diffusion Model for Robust Monocular 3D Object Detection,&#34; European Conference on Computer Vision (ECCV), 2024. [Paper] [Supp] [GitHub] [Poster] Hyung-Il Kim*, Kimin Yun*, Jun-Seok Yun, and Yuseok Bae, &#34;Task-Specific Adaptation of Segmentation Foundation Model via Prompt Learning,&#34; European Conference on Computer Vision (ECCV) Workshops, 2024. [Paper] Sooyoung Jang and Hyung-Il Kim, &#34;Efficient Deep Reinforcement Learning under Task Variations via Knowledge Transfer for Drone Control,&#34; ICT Express (ICTE), vol. 10, no. 3, pp. 576-582, 2024. [Paper] Seongyeop Kim, Hyung-Il Kim, and Yong Man Ro, &#34;Improving Open Set Recognition via Visual Prompts Distilled from Common-Sense Knowledge,&#34; AAAI Conference on Artificial Intelligence (AAAI), 2024. [Paper] Jun-Seok Yun, Min Hyuk Kim, Hyung-Il Kim, and Seok Bong Yoo, &#34;Kernel Adaptive Memory Network for Blind Video Super-Resolution,&#34; Expert Systems with Applications (ESWA), vol. 238, pp. 122252, 2024. [Paper] [GitHub] Enki Cho, Minkuk Kim, Hyung-Il Kim, Jinyoung Moon, and Seong Tae Kim, &#34;Exploiting Recollection Effects for Memory-based Video Object Segmentation,&#34; Image and Vision Computing (IMAVIS), vol. 140, pp. 104866, 2023. [Paper] Minho Park, Hyung-Il Kim, Hwa Jeon Song, and Dong-oh Kang, &#34;Augmenting Features via Contrastive Learning-based Generative Model for Long-Tailed Classification,&#34; IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, 2023. [Paper] Kimin Yun, Hyung-Il Kim, Kangmin Bae, and Jinyoung Moon, &#34;Background Memory-Assisted Zero-Shot Video Object Segmentation for Unmanned Aerial and Ground Vehicles,&#34; ETRI Journal, vol. 45, no. 3, pp. 795-910, 2023. [Paper] Kangmin Bae, Hyung-Il Kim, Yongjin Kwon, and Jinyoung Moon, &#34;Unsupervised Bidirectional Style Transfer Network using Local Feature Transform Module,&#34; IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2022. [Paper] Jung Uk Kim, Hyung-Il Kim, and Yong Man Ro, &#34;Stereoscopic Vision Recalling Memory for Monocular 3D Object Detection,&#34; IEEE Transactions on Image Processing (TIP), vol. 32, pp. 2749-2760, 2023. [Paper] Sooyoung Jang and Hyung-Il Kim, &#34;Supervised Pre-Training for Improved Stability in Deep Reinforcement Learning,&#34; ICT Express (ICTE), vol. 9, no. 1, pp. 51-56, 2023. [Paper] Hyung-Il Kim, Kimin Yun, and Yong Mn Ro, &#34;Face Shape-Guided Deep Feature Alignment for Face Recognition Robust to Face Misalignment,&#34; IEEE Transactions on Biometrics, Behavior, and Identity Science (TBIOM), vol. 4, no. 4, pp. 556-569, 2022. [Paper] Youngwan Lee, Joong-won Hwang, Hyung-Il Kim, Kimin Yun, Yongjin Kwon, Yuseok Bae, and Sung Ju Hwang, &#34;Localization Uncertainty Estimation for Anchor-Free Object Detection,&#34; European Conference on Computer Vision (ECCV) Workshops, 2022. [Paper] [GitHub] Sooyoung Jang and Hyung-Il Kim, &#34;Entropy-Aware Model Initialization for Effective Exploration in Deep Reinforcement Learning,&#34; Sensors, vol. 22, no. 15, pp. 5845, 2022. [Paper] Jun-Seok Yun, Youngju Na, Hee Hyeon Kim, Hyung-Il Kim, and Seok Bong Yoo, &#34;HAZE-Net: High-Frequency Attentive Super-Resolved Gaze Estimation in Low-Resolution Face Images,&#34; Asian Conference on Computer Vision (ACCV), 2022. [Paper] [Supp] [GitHub] Sangmin Lee, Hyung-Il Kim, and Yong Man Ro, &#34;Weakly Paired Associative Learning for Sound and Image Representations via Bimodal Associative Memory,&#34; IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. [Paper] [Supp] Youngwan Lee, Hyung-Il Kim, Kimin Yun, and Jinyoung Moon, &#34;Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization for Efficient Video Classification,&#34; IEEE Access, vol. 9, pp. 163054-163064, 2021. [Paper][GitHub] Kimin Yun, Hyung-Il Kim, Kangmin Bae, and Jongyoul Park, &#34;Unsupervised Moving Object Detection through Background Models for PTZ Camera,&#34; International Conference on Pattern Recognition (ICPR), 2021. [Paper] Sangmin Lee, Hak Gu Kim, Dae Hwi Choi, Hyung-Il Kim, and Yong Man Ro, &#34;Video Prediction Recalling Long-Term Motion Context via Memory Alignment Learning,&#34; IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021. [Paper][Supp][GitHub] Hyung-Il Kim and Seok Bong Yoo, &#34;Trends in Super-High-Definition Imaging Techniques based on Deep Neural Networks,&#34; Mathematics, vol. 8, no. 11, pp. 1907, 2020. [Paper] Kangmin Bae*, Kimin Yun*, Hyung-Il Kim, Youngwan Lee, and Jongyoul Park, &#34;Anti-Litter Surveillance based on Person Understanding via Multi-Task Learning,&#34; British Machine Vision Conference (BMVC), 2020. [Paper] Jinhyeok Jang, Dae Hoe Kim, Hyung-Il Kim, and Yong Man Ro, &#34;Color Channel-Wise Recurrent Learning for Facial Expression Recognition,&#34; IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2017. [Paper] Jeong-Jik Seo, Hyung-Il Kim, Wesley De Neve, and Yong Man Ro, &#34;Effective and Efficient Human Action Recognition using Dynamic Frame Skipping and Trajectory Rejection,&#34; Image and Vision Computing (IMAVIS), vol. 58, pp. 76-85, 2017. [Paper] Hyung-Il Kim and Yong Man Ro, &#34;Collaborative Facial Color Feature Learning of Multiple Color Spaces for Face Recognition,&#34; IEEE International Conference on Image Processing (ICIP), 2016. [Paper] Yeoreum Choi, Hyung-Il Kim, and Yong Man Ro, “Two-Step Learning of Deep Convolutional Neural Network for Discriminative Face Recognition under Varying Illumination,” IS&amp;T Electronic Imaging (EI), 2016. [Paper] Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, “Low-Power Face Detection for Smart Camera,” Theory and Applications of Smart Cameras, pp. 139-155, 2016. [Paper] Jeong-Jik Seo*, Hyung-Il Kim*, and Yong Man Ro, “Pose-Robust and Discriminative Feature Representation by Multi-Task Deep Learning for Multi-View Face Recognition,” IEEE International Symposium on Multimedia (ISM), 2015. [Paper] Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, &#34;Multispectral Texture Features from Visible and Near-Infrared Synthetic Face Images for Face Recognition,&#34; IEEE International Symposium on Multimedia (ISM), 2015. [Paper] Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, &#34;Face Image Assessment Learned with Objective and Relative Face Image Qualities for Improved Face Recognition,&#34; IEEE International Conference on Image Processing (ICIP), 2015. [Paper] Hyung-Il Kim, Jae Young Choi, Seung Ho Lee, and Yong Man Ro, &#34;Feature Scalability for a Low Complexity Face Recognition with Unconstrained Spatial Resolution,&#34; Multimedia Tools and Applications (MTAP), vol. 75, no. 12, pp. 6887-6908, 2015. [Paper] Jeong-Jik Seo, Wissam J. Baddar, Hyung-Il Kim, and Yong Man Ro, &#34;High-Speed Periodic Motion Reconstruction using an Off-The-Shelf Camera with Compensation for Rolling Shutter Effect,&#34; Pacific Rim Conference on Multimedia (PCM), 2015. [Paper] Jeong-Jik Seo, Jisoo Son, Hyung-Il Kim, Wesley De Neve, and Yong Man Ro, &#34;Efficient and Effective Human Action Recognition in Video through Motion Boundary Description with a Compact Set of Trajectories,&#34; IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2015. [Paper] Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, &#34;Investigating Cascaded Face Quality Assessment for Practical Face Recognition System,&#34; IEEE International Symposium on Multimedia (ISM), 2014. [Paper] Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, &#34;Adaptive Feature Extraction for Blurred Face Images in Facial Expression Recognition,&#34; IEEE International Conference on Image Processing (ICIP), 2014. [Paper] Hyung-Il Kim, Seung Ho Lee, Jung Ik Moon, Hyun-Sang Park, and Yong Man Ro, &#34;Face Detection for Low Power Event Detection in Intelligent Surveillance System,&#34; IEEE International Conference on Digital Signal Processing (DSP), 2014. [Paper] Seung Ho Lee, Hyung-Il Kim, Yong Man Ro, and Konstantinos N. Plataniotis, &#34;Using Color Texture Sparsity for Facial Expression Recognition,&#34; IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2013. [Paper] Seung Ho Lee, Hyung-Il Kim, and Yong Man Ro, &#34;A Comparative Study of Color Texture Features for Face Analysis,&#34; International Workshop on Computational Color Imaging (CCIW), 2013. [Paper] Domestic Publications # 한동현, 김형일, &#34;시각 인식을 위한 대형 비전 모델 조합에 따른 시너지 효과 분석,&#34; 영상처리 및 이해에 관한 워크샵(IPIU), 2025. 이찬, 한동현, 배유석, 천용석, 김형일, &#34;이미지 기반 문자인식 연동 한국어 대형 언어모델을 활용한 현수막 분류,&#34; 인공지능신호처리 학술대회, 2024. 오현호, 윤준석, 배유석, 김형일, &#34;다중 언어로 학습된 이미지 기반 문자인식 모델의 성능 분석,&#34; 대한전자공학회 하계학술대회, 2023. 문진영, 김형일, 이용주, &#34;온라인 행동 탐지 기술 동향,&#34; 전자통신동향분석, 36권, 2호, 75-82 페이지, 2021. [Paper] 문진영, 김형일, 박종열, &#34;시간적 행동 탐지 기술 동향,&#34; 전자통신동향분석, 35권, 3호, 20-33 페이지, 2020. [Paper] 김형일, 문진영, 박종열, &#34;딥러닝 기반 고성능 얼굴 인식 기술 동향,&#34; 전자통신동향분석, 33권, 4호, 45-53 페이지, 2018. [Paper] 김정욱, 김형일, 김성태, 노용만, &#34;객체의 움직임을 고려한 Siamese CNN 구조의 객체추적,&#34; 한국멀티미디어학회 추계학술발표대회, 2016. 최여름, 김형일, 노용만, &#34;NIR-VIS 이종의 얼굴인식을 위한 심층 정준상관분석을 이용한 지역적 얼굴 특징 학습 방법,&#34; 한국멀티미디어학회 추계학술발표대회, 2015. (우수논문상) 송주남, 이승호, 김형일, 노용만, &#34;대규모 비디오 감시 시스템에서 프라이버시 보호를 위한 저조도 환경에 강인한 고속의 얼굴검출,&#34; 한국멀티미디어학회 추계학술발표대회, 2015. 김동규, 이승호, 김형일, 노용만, &#34;파티클 필터에 기반한 강인한 얼굴추적을 위한 텍스처 특징 추출에 관한 연구,&#34; 한국정보처리학회 춘계학술발표대회, 2015. 이승호, 김형일, 박성영, 노용만, &#34;인물에 독립적인 표정인식을 위한 Action Unit 기반 얼굴특징에 관한 연구,&#34; 한국정보처리학회 춘계학술발표대회, 2015. (우수논문상) 이승호, 김형일, 노용만, &#34;텍스쳐 특징맵의 풀링 기법에 기반한 얼굴 포즈변화와 정렬오류에 강인한 얼굴인식 특징 추출 방법,&#34; 영상처리 및 이해에 관한 워크샵(IPIU), 2015. 김형일, 최여름, 노용만, &#34;희소표현 기반 출입통제를 위한 실시간 얼굴인식 방법,&#34; 영상처리 및 이해에 관한 워크샵(IPIU), 2015. 김동규, 김형일, 노용만, &#34;파티클 필터 기반의 얼굴추적에서 환경변화에 강인한 얼굴 특징에 관한 비교 연구,&#34; 한국멀티미디어학회 추계학술발표대회, 2014. 김형일, 이승호, 노용만, &#34;와일드 환경에서의 얼굴인식 기술 동향,&#34; 한국통신학회지(정보와 통신), 31권, 4호, 88-98 페이지, 2014. [Paper] 문정익, 이승호, 김형일, 노용만, &#34;텍스쳐에 기반하는 강인한 얼굴 검출 방법,&#34; 한국멀티미디어학회 추계학술발표대회, 2013. 김형일, 엄원용, 노용만, &#34;Sparse 표현을 이용한 X선 흡수 영상 개선,&#34; 한국멀티미디어학회논문지, 15권, 10호, 1205-1211 페이지, 2012. [Paper] 김형일, 엄원용, 노용만, &#34;Sparse 표현을 이용한 X선 흡수 영상 개선,&#34; 한국멀티미디어학회 춘계학술발표대회, 2012. (우수논문상) 김형일, 엄원용, 김대회, 노용만, &#34;Sparse 표현을 이용한 이중 에너지 X선 흡수 영상 잡음 제거,&#34; 한국정보처리학회 춘계학술발표대회, 2012.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="website">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="VCL Lab.">
  <meta name="twitter:description" content="International Publications # Minsu Kim, Hyung-Il Kim, and Yong Man Ro, &#34;Prompt Tuning of Deep Neural Networks for Speaker-Adaptive Visual Speech Recognition,&#34; IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), vol. 47, no. 2, pp. 1042-1055, 2025. [Paper] Sangmin Lee, Hyung-Il Kim, and Yong Man Ro, &#34;Text-Guided Distillation Learning to Diversify Video Embeddings for Text-Video Retrieval,&#34; Pattern Recognition (PR), vol. 156, pp. 110754, 2024. [Paper] Youngmin Oh, Hyung-Il Kim, Seong Tae Kim, and Jung Uk Kim, &#34;MonoWAD: Weather-Adaptive Diffusion Model for Robust Monocular 3D Object Detection,&#34; European Conference on Computer Vision (ECCV), 2024. [Paper] [Supp] [GitHub] [Poster] Hyung-Il Kim*, Kimin Yun*, Jun-Seok Yun, and Yuseok Bae, &#34;Task-Specific Adaptation of Segmentation Foundation Model via Prompt Learning,&#34; European Conference on Computer Vision (ECCV) Workshops, 2024. [Paper] Sooyoung Jang and Hyung-Il Kim, &#34;Efficient Deep Reinforcement Learning under Task Variations via Knowledge Transfer for Drone Control,&#34; ICT Express (ICTE), vol. 10, no. 3, pp. 576-582, 2024. [Paper] Seongyeop Kim, Hyung-Il Kim, and Yong Man Ro, &#34;Improving Open Set Recognition via Visual Prompts Distilled from Common-Sense Knowledge,&#34; AAAI Conference on Artificial Intelligence (AAAI), 2024. [Paper] Jun-Seok Yun, Min Hyuk Kim, Hyung-Il Kim, and Seok Bong Yoo, &#34;Kernel Adaptive Memory Network for Blind Video Super-Resolution,&#34; Expert Systems with Applications (ESWA), vol. 238, pp. 122252, 2024. [Paper] [GitHub] Enki Cho, Minkuk Kim, Hyung-Il Kim, Jinyoung Moon, and Seong Tae Kim, &#34;Exploiting Recollection Effects for Memory-based Video Object Segmentation,&#34; Image and Vision Computing (IMAVIS), vol. 140, pp. 104866, 2023. [Paper] Minho Park, Hyung-Il Kim, Hwa Jeon Song, and Dong-oh Kang, &#34;Augmenting Features via Contrastive Learning-based Generative Model for Long-Tailed Classification,&#34; IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, 2023. [Paper] Kimin Yun, Hyung-Il Kim, Kangmin Bae, and Jinyoung Moon, &#34;Background Memory-Assisted Zero-Shot Video Object Segmentation for Unmanned Aerial and Ground Vehicles,&#34; ETRI Journal, vol. 45, no. 3, pp. 795-910, 2023. [Paper] Kangmin Bae, Hyung-Il Kim, Yongjin Kwon, and Jinyoung Moon, &#34;Unsupervised Bidirectional Style Transfer Network using Local Feature Transform Module,&#34; IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2022. [Paper] Jung Uk Kim, Hyung-Il Kim, and Yong Man Ro, &#34;Stereoscopic Vision Recalling Memory for Monocular 3D Object Detection,&#34; IEEE Transactions on Image Processing (TIP), vol. 32, pp. 2749-2760, 2023. [Paper] Sooyoung Jang and Hyung-Il Kim, &#34;Supervised Pre-Training for Improved Stability in Deep Reinforcement Learning,&#34; ICT Express (ICTE), vol. 9, no. 1, pp. 51-56, 2023. [Paper] Hyung-Il Kim, Kimin Yun, and Yong Mn Ro, &#34;Face Shape-Guided Deep Feature Alignment for Face Recognition Robust to Face Misalignment,&#34; IEEE Transactions on Biometrics, Behavior, and Identity Science (TBIOM), vol. 4, no. 4, pp. 556-569, 2022. [Paper] Youngwan Lee, Joong-won Hwang, Hyung-Il Kim, Kimin Yun, Yongjin Kwon, Yuseok Bae, and Sung Ju Hwang, &#34;Localization Uncertainty Estimation for Anchor-Free Object Detection,&#34; European Conference on Computer Vision (ECCV) Workshops, 2022. [Paper] [GitHub] Sooyoung Jang and Hyung-Il Kim, &#34;Entropy-Aware Model Initialization for Effective Exploration in Deep Reinforcement Learning,&#34; Sensors, vol. 22, no. 15, pp. 5845, 2022. [Paper] Jun-Seok Yun, Youngju Na, Hee Hyeon Kim, Hyung-Il Kim, and Seok Bong Yoo, &#34;HAZE-Net: High-Frequency Attentive Super-Resolved Gaze Estimation in Low-Resolution Face Images,&#34; Asian Conference on Computer Vision (ACCV), 2022. [Paper] [Supp] [GitHub] Sangmin Lee, Hyung-Il Kim, and Yong Man Ro, &#34;Weakly Paired Associative Learning for Sound and Image Representations via Bimodal Associative Memory,&#34; IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. [Paper] [Supp] Youngwan Lee, Hyung-Il Kim, Kimin Yun, and Jinyoung Moon, &#34;Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization for Efficient Video Classification,&#34; IEEE Access, vol. 9, pp. 163054-163064, 2021. [Paper][GitHub] Kimin Yun, Hyung-Il Kim, Kangmin Bae, and Jongyoul Park, &#34;Unsupervised Moving Object Detection through Background Models for PTZ Camera,&#34; International Conference on Pattern Recognition (ICPR), 2021. [Paper] Sangmin Lee, Hak Gu Kim, Dae Hwi Choi, Hyung-Il Kim, and Yong Man Ro, &#34;Video Prediction Recalling Long-Term Motion Context via Memory Alignment Learning,&#34; IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021. [Paper][Supp][GitHub] Hyung-Il Kim and Seok Bong Yoo, &#34;Trends in Super-High-Definition Imaging Techniques based on Deep Neural Networks,&#34; Mathematics, vol. 8, no. 11, pp. 1907, 2020. [Paper] Kangmin Bae*, Kimin Yun*, Hyung-Il Kim, Youngwan Lee, and Jongyoul Park, &#34;Anti-Litter Surveillance based on Person Understanding via Multi-Task Learning,&#34; British Machine Vision Conference (BMVC), 2020. [Paper] Jinhyeok Jang, Dae Hoe Kim, Hyung-Il Kim, and Yong Man Ro, &#34;Color Channel-Wise Recurrent Learning for Facial Expression Recognition,&#34; IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2017. [Paper] Jeong-Jik Seo, Hyung-Il Kim, Wesley De Neve, and Yong Man Ro, &#34;Effective and Efficient Human Action Recognition using Dynamic Frame Skipping and Trajectory Rejection,&#34; Image and Vision Computing (IMAVIS), vol. 58, pp. 76-85, 2017. [Paper] Hyung-Il Kim and Yong Man Ro, &#34;Collaborative Facial Color Feature Learning of Multiple Color Spaces for Face Recognition,&#34; IEEE International Conference on Image Processing (ICIP), 2016. [Paper] Yeoreum Choi, Hyung-Il Kim, and Yong Man Ro, “Two-Step Learning of Deep Convolutional Neural Network for Discriminative Face Recognition under Varying Illumination,” IS&amp;T Electronic Imaging (EI), 2016. [Paper] Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, “Low-Power Face Detection for Smart Camera,” Theory and Applications of Smart Cameras, pp. 139-155, 2016. [Paper] Jeong-Jik Seo*, Hyung-Il Kim*, and Yong Man Ro, “Pose-Robust and Discriminative Feature Representation by Multi-Task Deep Learning for Multi-View Face Recognition,” IEEE International Symposium on Multimedia (ISM), 2015. [Paper] Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, &#34;Multispectral Texture Features from Visible and Near-Infrared Synthetic Face Images for Face Recognition,&#34; IEEE International Symposium on Multimedia (ISM), 2015. [Paper] Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, &#34;Face Image Assessment Learned with Objective and Relative Face Image Qualities for Improved Face Recognition,&#34; IEEE International Conference on Image Processing (ICIP), 2015. [Paper] Hyung-Il Kim, Jae Young Choi, Seung Ho Lee, and Yong Man Ro, &#34;Feature Scalability for a Low Complexity Face Recognition with Unconstrained Spatial Resolution,&#34; Multimedia Tools and Applications (MTAP), vol. 75, no. 12, pp. 6887-6908, 2015. [Paper] Jeong-Jik Seo, Wissam J. Baddar, Hyung-Il Kim, and Yong Man Ro, &#34;High-Speed Periodic Motion Reconstruction using an Off-The-Shelf Camera with Compensation for Rolling Shutter Effect,&#34; Pacific Rim Conference on Multimedia (PCM), 2015. [Paper] Jeong-Jik Seo, Jisoo Son, Hyung-Il Kim, Wesley De Neve, and Yong Man Ro, &#34;Efficient and Effective Human Action Recognition in Video through Motion Boundary Description with a Compact Set of Trajectories,&#34; IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2015. [Paper] Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, &#34;Investigating Cascaded Face Quality Assessment for Practical Face Recognition System,&#34; IEEE International Symposium on Multimedia (ISM), 2014. [Paper] Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, &#34;Adaptive Feature Extraction for Blurred Face Images in Facial Expression Recognition,&#34; IEEE International Conference on Image Processing (ICIP), 2014. [Paper] Hyung-Il Kim, Seung Ho Lee, Jung Ik Moon, Hyun-Sang Park, and Yong Man Ro, &#34;Face Detection for Low Power Event Detection in Intelligent Surveillance System,&#34; IEEE International Conference on Digital Signal Processing (DSP), 2014. [Paper] Seung Ho Lee, Hyung-Il Kim, Yong Man Ro, and Konstantinos N. Plataniotis, &#34;Using Color Texture Sparsity for Facial Expression Recognition,&#34; IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2013. [Paper] Seung Ho Lee, Hyung-Il Kim, and Yong Man Ro, &#34;A Comparative Study of Color Texture Features for Face Analysis,&#34; International Workshop on Computational Color Imaging (CCIW), 2013. [Paper] Domestic Publications # 한동현, 김형일, &#34;시각 인식을 위한 대형 비전 모델 조합에 따른 시너지 효과 분석,&#34; 영상처리 및 이해에 관한 워크샵(IPIU), 2025. 이찬, 한동현, 배유석, 천용석, 김형일, &#34;이미지 기반 문자인식 연동 한국어 대형 언어모델을 활용한 현수막 분류,&#34; 인공지능신호처리 학술대회, 2024. 오현호, 윤준석, 배유석, 김형일, &#34;다중 언어로 학습된 이미지 기반 문자인식 모델의 성능 분석,&#34; 대한전자공학회 하계학술대회, 2023. 문진영, 김형일, 이용주, &#34;온라인 행동 탐지 기술 동향,&#34; 전자통신동향분석, 36권, 2호, 75-82 페이지, 2021. [Paper] 문진영, 김형일, 박종열, &#34;시간적 행동 탐지 기술 동향,&#34; 전자통신동향분석, 35권, 3호, 20-33 페이지, 2020. [Paper] 김형일, 문진영, 박종열, &#34;딥러닝 기반 고성능 얼굴 인식 기술 동향,&#34; 전자통신동향분석, 33권, 4호, 45-53 페이지, 2018. [Paper] 김정욱, 김형일, 김성태, 노용만, &#34;객체의 움직임을 고려한 Siamese CNN 구조의 객체추적,&#34; 한국멀티미디어학회 추계학술발표대회, 2016. 최여름, 김형일, 노용만, &#34;NIR-VIS 이종의 얼굴인식을 위한 심층 정준상관분석을 이용한 지역적 얼굴 특징 학습 방법,&#34; 한국멀티미디어학회 추계학술발표대회, 2015. (우수논문상) 송주남, 이승호, 김형일, 노용만, &#34;대규모 비디오 감시 시스템에서 프라이버시 보호를 위한 저조도 환경에 강인한 고속의 얼굴검출,&#34; 한국멀티미디어학회 추계학술발표대회, 2015. 김동규, 이승호, 김형일, 노용만, &#34;파티클 필터에 기반한 강인한 얼굴추적을 위한 텍스처 특징 추출에 관한 연구,&#34; 한국정보처리학회 춘계학술발표대회, 2015. 이승호, 김형일, 박성영, 노용만, &#34;인물에 독립적인 표정인식을 위한 Action Unit 기반 얼굴특징에 관한 연구,&#34; 한국정보처리학회 춘계학술발표대회, 2015. (우수논문상) 이승호, 김형일, 노용만, &#34;텍스쳐 특징맵의 풀링 기법에 기반한 얼굴 포즈변화와 정렬오류에 강인한 얼굴인식 특징 추출 방법,&#34; 영상처리 및 이해에 관한 워크샵(IPIU), 2015. 김형일, 최여름, 노용만, &#34;희소표현 기반 출입통제를 위한 실시간 얼굴인식 방법,&#34; 영상처리 및 이해에 관한 워크샵(IPIU), 2015. 김동규, 김형일, 노용만, &#34;파티클 필터 기반의 얼굴추적에서 환경변화에 강인한 얼굴 특징에 관한 비교 연구,&#34; 한국멀티미디어학회 추계학술발표대회, 2014. 김형일, 이승호, 노용만, &#34;와일드 환경에서의 얼굴인식 기술 동향,&#34; 한국통신학회지(정보와 통신), 31권, 4호, 88-98 페이지, 2014. [Paper] 문정익, 이승호, 김형일, 노용만, &#34;텍스쳐에 기반하는 강인한 얼굴 검출 방법,&#34; 한국멀티미디어학회 추계학술발표대회, 2013. 김형일, 엄원용, 노용만, &#34;Sparse 표현을 이용한 X선 흡수 영상 개선,&#34; 한국멀티미디어학회논문지, 15권, 10호, 1205-1211 페이지, 2012. [Paper] 김형일, 엄원용, 노용만, &#34;Sparse 표현을 이용한 X선 흡수 영상 개선,&#34; 한국멀티미디어학회 춘계학술발표대회, 2012. (우수논문상) 김형일, 엄원용, 김대회, 노용만, &#34;Sparse 표현을 이용한 이중 에너지 X선 흡수 영상 잡음 제거,&#34; 한국정보처리학회 춘계학술발표대회, 2012.">

  
  

  
  
  
  
  

<script src="/vcl/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js" integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj&#43;KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script>






















  
  



  
  
  <meta name="theme-color"/>
  
  
</head>
<body
  class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600">
  <div id="the-top" class="absolute flex self-center">
    <a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
      href="#main-content"><span
        class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a>
  </div>
  
  
  <div style="padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px"
    class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3">
    
    <div class="flex flex-1 items-center justify-between">
        <nav class="flex space-x-3">

            
            <a href="/vcl/" class="text-base font-medium text-gray-500 hover:text-gray-900">VCL Lab.</a>
            

        </nav>
        <nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12">

            
            
            
  <a href="/vcl/people"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <p class="text-base font-medium" title="">
        People
    </p>
</a>



            
            
  <a href="/vcl/research/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <p class="text-base font-medium" title="">
        Research
    </p>
</a>



            
            
  <a href="/vcl/publications/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <p class="text-base font-medium" title="">
        Publications
    </p>
</a>



            
            
  <a href="/vcl/courses/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <p class="text-base font-medium" title="">
        Courses
    </p>
</a>



            
            
  <a href="/vcl/joining/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <p class="text-base font-medium" title="">
        Joining
    </p>
</a>



            
            

            


            
            <button id="search-button" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            


            
            

        </nav>
        <div class="flex md:hidden items-center space-x-5 md:ml-12 h-12">

            <span></span>

            


            
            <button id="search-button-mobile" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            

            
            

        </div>
    </div>
    <div class="-my-2 -mr-2 md:hidden">

        <label id="menu-button" class="block">
            
            <div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400">
                

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416C433.7 64 448 78.33 448 96C448 113.7 433.7 128 416 128H32C14.33 128 0 113.7 0 96zM0 256C0 238.3 14.33 224 32 224H416C433.7 224 448 238.3 448 256C448 273.7 433.7 288 416 288H32C14.33 288 0 273.7 0 256zM416 448H32C14.33 448 0 433.7 0 416C0 398.3 14.33 384 32 384H416C433.7 384 448 398.3 448 416C448 433.7 433.7 448 416 448z"/></svg>

  </span>


            </div>
            <div id="menu-wrapper" style="padding-top:5px;"
                class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50">
                <ul
                    class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl">

                    <li id="menu-close-button">
                        <span
                            class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>

</span>
                    </li>

                    

                    
  <li class="mt-1">
    <a href="/vcl/people"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            People
        </p>
    </a>
</li>




                    

                    
  <li class="mt-1">
    <a href="/vcl/research/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Research
        </p>
    </a>
</li>




                    

                    
  <li class="mt-1">
    <a href="/vcl/publications/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Publications
        </p>
    </a>
</li>




                    

                    
  <li class="mt-1">
    <a href="/vcl/courses/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Courses
        </p>
    </a>
</li>




                    

                    
  <li class="mt-1">
    <a href="/vcl/joining/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Joining
        </p>
    </a>
</li>




                    

                </ul>
                
                

            </div>
        </label>
    </div>
</div>





  
  <div class="relative flex flex-col grow">
    <main id="main-content" class="grow">
      



<header>
  
  <h1 class="mt-5 text-4xl font-extrabold text-neutral-900 dark:text-neutral"></h1>
  <div class="mt-1 mb-2 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
    





















<div class="flex flex-row flex-wrap items-center">
  
  
</div>


  </div>
  
  
    
    
      
      
    
  <script>
    var oid = "views_publications\/papers\/_index.md"
    var oid_likes = "likes_publications\/papers\/_index.md"
  </script>
  
  
  <script type="text/javascript" src="/vcl/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js" integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q&#43;oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script>
  
</header>

<section class="mt-0 prose flex max-w-full flex-col dark:prose-invert lg:flex-row">
  
  <div class="min-w-0 min-h-0 max-w-prose">
    <br/>


<h2 class="relative group"><span style="color: rgb(243, 123, 165); font-weight: bold;">International Publications</span> 
    <div id="span-stylecolor-rgb243-123-165-font-weight-boldinternational-publicationsspan" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#span-stylecolor-rgb243-123-165-font-weight-boldinternational-publicationsspan" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<table style="width: 100%; border-collapse: collapse;">
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Minsu Kim, Hyung-Il Kim, and Yong Man Ro, "<strong>Prompt Tuning of Deep Neural Networks for Speaker-Adaptive Visual Speech Recognition</strong>," IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), vol. 47, no. 2, pp. 1042-1055, 2025. [<a href="https://ieeexplore.ieee.org/abstract/document/10726873" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>] 
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Sangmin Lee, Hyung-Il Kim, and Yong Man Ro, "<strong>Text-Guided Distillation Learning to Diversify Video Embeddings for Text-Video Retrieval</strong>," Pattern Recognition (PR), vol. 156, pp. 110754, 2024. [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320324005053" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>] 
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Youngmin Oh, Hyung-Il Kim, Seong Tae Kim, and Jung Uk Kim, "<strong>MonoWAD: Weather-Adaptive Diffusion Model for Robust Monocular 3D Object Detection</strong>," European Conference on Computer Vision (ECCV), 2024. [<a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01600.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>] [<a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01600-supp.pdf" style="text-decoration: none; color: #007bff;"><u>Supp</u></a>] [<a href="https://github.com/VisualAIKHU/MonoWAD" style="text-decoration: none; color: #007bff;"><u>GitHub</u></a>] [<a href="https://eccv.ecva.net/media/PosterPDFs/ECCV%202024/1374.png?t=1726139205.979201" style="text-decoration: none; color: #007bff;"><u>Poster</u></a>] 
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Hyung-Il Kim*, Kimin Yun*, Jun-Seok Yun, and Yuseok Bae, "<strong>Task-Specific Adaptation of Segmentation Foundation Model via Prompt Learning</strong>," European Conference on Computer Vision (ECCV) Workshops, 2024. [<a href="https://arxiv.org/pdf/2403.09199" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>] 
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Sooyoung Jang and Hyung-Il Kim, "<strong>Efficient Deep Reinforcement Learning under Task Variations via Knowledge Transfer for Drone Control</strong>," ICT Express (ICTE), vol. 10, no. 3, pp. 576-582, 2024. [<a href="https://www.sciencedirect.com/science/article/pii/S240595952400033X/pdfft?md5=7d370e1bd566b1fe70dbc9a76bf4c077&pid=1-s2.0-S240595952400033X-main.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>] 
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Seongyeop Kim, Hyung-Il Kim, and Yong Man Ro, "<strong>Improving Open Set Recognition via Visual Prompts Distilled from Common-Sense Knowledge</strong>," AAAI Conference on Artificial Intelligence (AAAI), 2024. [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28058" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>] 
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Jun-Seok Yun, Min Hyuk Kim, Hyung-Il Kim, and Seok Bong Yoo, "<strong>Kernel Adaptive Memory Network for Blind Video Super-Resolution</strong>," Expert Systems with Applications (ESWA), vol. 238, pp. 122252, 2024. [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423027549" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>] [<a href="https://github.com/dbseorms16/KeMoVSR" style="text-decoration: none; color: #007bff;"><u>GitHub</u></a>] 
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Enki Cho, Minkuk Kim, Hyung-Il Kim, Jinyoung Moon, and Seong Tae Kim, "<strong>Exploiting Recollection Effects for Memory-based Video Object Segmentation</strong>," Image and Vision Computing (IMAVIS), vol. 140, pp. 104866, 2023. [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0262885623002408" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Minho Park, Hyung-Il Kim, Hwa Jeon Song, and Dong-oh Kang, "<strong>Augmenting Features via Contrastive Learning-based Generative Model for Long-Tailed Classification</strong>," IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, 2023. [<a href="https://openaccess.thecvf.com/content/ICCV2023W/LIMIT/papers/Park_Augmenting_Features_via_Contrastive_Learning-Based_Generative_Model_for_Long-Tailed_Classification_ICCVW_2023_paper.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>] 
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Kimin Yun, Hyung-Il Kim, Kangmin Bae, and Jinyoung Moon, "<strong>Background Memory-Assisted Zero-Shot Video Object Segmentation for Unmanned Aerial and Ground Vehicles</strong>," ETRI Journal, vol. 45, no. 3, pp. 795-910, 2023. [<a href="https://onlinelibrary.wiley.com/doi/epdf/10.4218/etrij.2023-0115" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Kangmin Bae, Hyung-Il Kim, Yongjin Kwon, and Jinyoung Moon, "<strong>Unsupervised Bidirectional Style Transfer Network using Local Feature Transform Module</strong>," IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2022. [<a href="https://openaccess.thecvf.com/content/CVPR2023W/GCV/papers/Bae_Unsupervised_Bidirectional_Style_Transfer_Network_Using_Local_Feature_Transform_Module_CVPRW_2023_paper.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>] 
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Jung Uk Kim, Hyung-Il Kim, and Yong Man Ro, "<strong>Stereoscopic Vision Recalling Memory for Monocular 3D Object Detection</strong>," IEEE Transactions on Image Processing (TIP), vol. 32, pp. 2749-2760, 2023. [<a href="https://ieeexplore.ieee.org/abstract/document/10124171" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Sooyoung Jang and Hyung-Il Kim, "<strong>Supervised Pre-Training for Improved Stability in Deep Reinforcement Learning</strong>," ICT Express (ICTE), vol. 9, no. 1, pp. 51-56, 2023. [<a href="https://www.sciencedirect.com/science/article/pii/S2405959521001806/pdfft?md5=c68cc578b275a1857531dbc72891f922&pid=1-s2.0-S2405959521001806-main.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Hyung-Il Kim, Kimin Yun, and Yong Mn Ro, "<strong>Face Shape-Guided Deep Feature Alignment for Face Recognition Robust to Face Misalignment</strong>," IEEE Transactions on Biometrics, Behavior, and Identity Science (TBIOM), vol. 4, no. 4, pp. 556-569, 2022. [<a href="https://ieeexplore.ieee.org/abstract/document/9916518" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Youngwan Lee, Joong-won Hwang, Hyung-Il Kim, Kimin Yun, Yongjin Kwon, Yuseok Bae, and Sung Ju Hwang, "<strong>Localization Uncertainty Estimation for Anchor-Free Object Detection</strong>," European Conference on Computer Vision (ECCV) Workshops, 2022. [<a href="https://arxiv.org/pdf/2006.15607" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>] [<a href="https://github.com/youngwanLEE/UAD" style="text-decoration: none; color: #007bff;"><u>GitHub</u></a>] 
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Sooyoung Jang and Hyung-Il Kim, "<strong>Entropy-Aware Model Initialization for Effective Exploration in Deep Reinforcement Learning</strong>," Sensors, vol. 22, no. 15, pp. 5845, 2022. [<a href="https://www.mdpi.com/1424-8220/22/15/5845" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Jun-Seok Yun, Youngju Na, Hee Hyeon Kim, Hyung-Il Kim, and Seok Bong Yoo, "<strong>HAZE-Net: High-Frequency Attentive Super-Resolved Gaze Estimation in Low-Resolution Face Images</strong>," Asian Conference on Computer Vision (ACCV), 2022. [<a href="https://openaccess.thecvf.com/content/ACCV2022/papers/Yun_HAZE-Net_High-Frequency_Attentive_Super-Resolved_Gaze_Estimation_in_Low-Resolution_Face_Images_ACCV_2022_paper.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>] [<a href="https://openaccess.thecvf.com/content/ACCV2022/supplemental/Yun_HAZE-Net_High-Frequency_Attentive_ACCV_2022_supplemental.zip" style="text-decoration: none; color: #007bff;"><u>Supp</u></a>] [<a href="https://github.com/dbseorms16/HAZE_Net" style="text-decoration: none; color: #007bff;"><u>GitHub</u></a>] 
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Sangmin Lee, Hyung-Il Kim, and Yong Man Ro, "<strong>Weakly Paired Associative Learning for Sound and Image Representations via Bimodal Associative Memory</strong>," IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022. [<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Weakly_Paired_Associative_Learning_for_Sound_and_Image_Representations_via_CVPR_2022_paper.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>] [<a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Weakly_Paired_Associative_CVPR_2022_supplemental.pdf" style="text-decoration: none; color: #007bff;"><u>Supp</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Youngwan Lee, Hyung-Il Kim, Kimin Yun, and Jinyoung Moon, "<strong>Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization for Efficient Video Classification</strong>," IEEE Access, vol. 9, pp. 163054-163064, 2021. [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9638459" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>][<a href="https://github.com/youngwanLEE/VoV3D" style="text-decoration: none; color: #007bff;"><u>GitHub</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Kimin Yun, Hyung-Il Kim, Kangmin Bae, and Jongyoul Park, "<strong>Unsupervised Moving Object Detection through Background Models for PTZ Camera</strong>," International Conference on Pattern Recognition (ICPR), 2021. [<a href="https://ieeexplore.ieee.org/abstract/document/9413085?casa_token=cC6MmtJ0NEYAAAAA:nJqMinghjSgHW6CUjZjZx309rD1JlArNvgY4EfeMmQ7qs8oWU0aWNH8chBzEAgeHlArXePBavEc" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Sangmin Lee, Hak Gu Kim, Dae Hwi Choi, Hyung-Il Kim, and Yong Man Ro, "<strong>Video Prediction Recalling Long-Term Motion Context via Memory Alignment Learning</strong>," IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021. [<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Video_Prediction_Recalling_Long-Term_Motion_Context_via_Memory_Alignment_Learning_CVPR_2021_paper.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>][<a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Lee_Video_Prediction_Recalling_CVPR_2021_supplemental.pdf" style="text-decoration: none; color: #007bff;"><u>Supp</u></a>][<a href="https://github.com/sangmin-git/LMC-Memory" style="text-decoration: none; color: #007bff;"><u>GitHub</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Hyung-Il Kim and Seok Bong Yoo, "<strong>Trends in Super-High-Definition Imaging Techniques based on Deep Neural Networks</strong>," Mathematics, vol. 8, no. 11, pp. 1907, 2020. [<a href="https://www.mdpi.com/2227-7390/8/11/1907" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Kangmin Bae*, Kimin Yun*, Hyung-Il Kim, Youngwan Lee, and Jongyoul Park, "<strong>Anti-Litter Surveillance based on Person Understanding via Multi-Task Learning</strong>," British Machine Vision Conference (BMVC), 2020. [<a href="https://www.bmvc2020-conference.com/assets/papers/0279.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Jinhyeok Jang, Dae Hoe Kim, Hyung-Il Kim, and Yong Man Ro, "<strong>Color Channel-Wise Recurrent Learning for Facial Expression Recognition</strong>," IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2017. [<a href="https://ieeexplore.ieee.org/abstract/document/7952353" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Jeong-Jik Seo, Hyung-Il Kim, Wesley De Neve, and Yong Man Ro, "<strong>Effective and Efficient Human Action Recognition using Dynamic Frame Skipping and Trajectory Rejection</strong>," Image and Vision Computing (IMAVIS), vol. 58, pp. 76-85, 2017. [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0262885616301007" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Hyung-Il Kim and Yong Man Ro, "<strong>Collaborative Facial Color Feature Learning of Multiple Color Spaces for Face Recognition</strong>," IEEE International Conference on Image Processing (ICIP), 2016. [<a href="https://ieeexplore.ieee.org/abstract/document/7532642" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Yeoreum Choi, Hyung-Il Kim, and Yong Man Ro, “<strong>Two-Step Learning of Deep Convolutional Neural Network for Discriminative Face Recognition under Varying Illumination</strong>,” IS&T Electronic Imaging (EI), 2016. [<a href="https://library.imaging.org/admin/apis/public/api/ist/website/downloadArticle/ei/28/11/art00005" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, “<strong>Low-Power Face Detection for Smart Camera</strong>,” Theory and Applications of Smart Cameras, pp. 139-155, 2016. [<a href="https://link.springer.com/chapter/10.1007/978-94-017-9987-4_7" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Jeong-Jik Seo*, Hyung-Il Kim*, and Yong Man Ro, “<strong>Pose-Robust and Discriminative Feature Representation by Multi-Task Deep Learning for Multi-View Face Recognition</strong>,” IEEE International Symposium on Multimedia (ISM), 2015. [<a href="https://ieeexplore.ieee.org/abstract/document/7442319" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, "<strong>Multispectral Texture Features from Visible and Near-Infrared Synthetic Face Images for Face Recognition</strong>," IEEE International Symposium on Multimedia (ISM), 2015. [<a href="https://ieeexplore.ieee.org/abstract/document/7442402" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, "<strong>Face Image Assessment Learned with Objective and Relative Face Image Qualities for Improved Face Recognition</strong>," IEEE International Conference on Image Processing (ICIP), 2015. [<a href="https://ieeexplore.ieee.org/abstract/document/7351562" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Hyung-Il Kim, Jae Young Choi, Seung Ho Lee, and Yong Man Ro, "<strong>Feature Scalability for a Low Complexity Face Recognition with Unconstrained Spatial Resolution</strong>," Multimedia Tools and Applications (MTAP), vol. 75, no. 12, pp. 6887-6908, 2015. [<a href="https://link.springer.com/article/10.1007/s11042-015-2616-3" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Jeong-Jik Seo, Wissam J. Baddar, Hyung-Il Kim, and Yong Man Ro, "<strong>High-Speed Periodic Motion Reconstruction using an Off-The-Shelf Camera with Compensation for Rolling Shutter Effect</strong>," Pacific Rim Conference on Multimedia (PCM), 2015. [<a href="https://link.springer.com/chapter/10.1007/978-3-319-24078-7_31" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Jeong-Jik Seo, Jisoo Son, Hyung-Il Kim, Wesley De Neve, and Yong Man Ro, "<strong>Efficient and Effective Human Action Recognition in Video through Motion Boundary Description with a Compact Set of Trajectories</strong>," IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2015.  [<a href="https://ieeexplore.ieee.org/document/7163123" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, "<strong>Investigating Cascaded Face Quality Assessment for Practical Face Recognition System</strong>," IEEE International Symposium on Multimedia (ISM), 2014.  [<a href="https://ieeexplore.ieee.org/document/7033058" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Hyung-Il Kim, Seung Ho Lee, and Yong Man Ro, "<strong>Adaptive Feature Extraction for Blurred Face Images in Facial Expression Recognition</strong>," IEEE International Conference on Image Processing (ICIP), 2014.  [<a href="https://ieeexplore.ieee.org/document/7026205" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Hyung-Il Kim, Seung Ho Lee, Jung Ik Moon, Hyun-Sang Park, and Yong Man Ro, "<strong>Face Detection for Low Power Event Detection in Intelligent Surveillance System</strong>," IEEE International Conference on Digital Signal Processing (DSP), 2014.  [<a href="https://ieeexplore.ieee.org/document/6900728" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr>  
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Seung Ho Lee, Hyung-Il Kim, Yong Man Ro, and Konstantinos N. Plataniotis, "<strong>Using   Color Texture Sparsity for Facial Expression Recognition</strong>," IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2013. [<a href="https://ieeexplore.ieee.org/abstract/document/6553769" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr>  
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          Seung Ho Lee, Hyung-Il Kim, and Yong Man Ro, "<strong>A Comparative Study of Color Texture Features for Face Analysis</strong>," International Workshop on Computational Color Imaging (CCIW), 2013. [<a href="https://link.springer.com/chapter/10.1007/978-3-642-36700-7_21" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr>  
    </table>


<h2 class="relative group"><span style="color: rgb(243, 123, 165); font-weight: bold;">Domestic Publications</span> 
    <div id="span-stylecolor-rgb243-123-165-font-weight-bolddomestic-publicationsspan" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#span-stylecolor-rgb243-123-165-font-weight-bolddomestic-publicationsspan" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<table style="width: 100%; border-collapse: collapse;">
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          한동현, 김형일, "<strong>시각 인식을 위한 대형 비전 모델 조합에 따른 시너지 효과 분석</strong>," 영상처리 및 이해에 관한 워크샵(IPIU), 2025. 
        </td>
      </tr>  
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          이찬, 한동현, 배유석, 천용석, 김형일, "<strong>이미지 기반 문자인식 연동 한국어 대형 언어모델을 활용한 현수막 분류</strong>," 인공지능신호처리 학술대회, 2024.
        </td>
      </tr>  
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          오현호, 윤준석, 배유석, 김형일, "<strong>다중 언어로 학습된 이미지 기반 문자인식 모델의 성능 분석</strong>," 대한전자공학회 하계학술대회, 2023. 
        </td>
      </tr>  
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          문진영, 김형일, 이용주, "<strong>온라인 행동 탐지 기술 동향</strong>," 전자통신동향분석, 36권, 2호, 75-82 페이지, 2021. [<a href="https://ettrends.etri.re.kr/ettrends/189/0905189008/075-082_%EB%AC%B8%EC%A7%84%EC%98%81.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]  
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          문진영, 김형일, 박종열, "<strong>시간적 행동 탐지 기술 동향</strong>," 전자통신동향분석, 35권, 3호, 20-33 페이지, 2020. [<a href="https://ettrends.etri.re.kr/ettrends/183/0905183003/35-3_20-33.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]  
        </td>
      </tr>  
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          김형일, 문진영, 박종열, "<strong>딥러닝 기반 고성능 얼굴 인식 기술 동향</strong>," 전자통신동향분석, 33권, 4호, 45-53 페이지, 2018. [<a href="https://ettrends.etri.re.kr/ettrends/172/0905172005/33-4_43-53.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]  
        </td>
      </tr>  
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          김정욱, 김형일, 김성태, 노용만, "<strong>객체의 움직임을 고려한 Siamese CNN 구조의 객체추적</strong>," 한국멀티미디어학회 추계학술발표대회, 2016. 
        </td>
      </tr>  
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          최여름, 김형일, 노용만, "<strong>NIR-VIS 이종의 얼굴인식을 위한 심층 정준상관분석을 이용한 지역적 얼굴 특징 학습 방법</strong>," 한국멀티미디어학회 추계학술발표대회, 2015. (우수논문상)
        </td>
      </tr>  
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          송주남, 이승호, 김형일, 노용만, "<strong>대규모 비디오 감시 시스템에서 프라이버시 보호를 위한 저조도 환경에 강인한 고속의 얼굴검출</strong>," 한국멀티미디어학회 추계학술발표대회, 2015.
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          김동규, 이승호, 김형일, 노용만, "<strong>파티클 필터에 기반한 강인한 얼굴추적을 위한 텍스처 특징 추출에 관한 연구</strong>," 한국정보처리학회 춘계학술발표대회, 2015.
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          이승호, 김형일, 박성영, 노용만, "<strong>인물에 독립적인 표정인식을 위한 Action Unit 기반 얼굴특징에 관한 연구</strong>," 한국정보처리학회 춘계학술발표대회, 2015. (우수논문상)
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          이승호, 김형일, 노용만, "<strong>텍스쳐 특징맵의 풀링 기법에 기반한 얼굴 포즈변화와 정렬오류에 강인한 얼굴인식 특징 추출 방법</strong>," 영상처리 및 이해에 관한 워크샵(IPIU), 2015.
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          김형일, 최여름, 노용만, "<strong>희소표현 기반 출입통제를 위한 실시간 얼굴인식 방법</strong>," 영상처리 및 이해에 관한 워크샵(IPIU), 2015.
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          김동규, 김형일, 노용만, "<strong>파티클 필터 기반의 얼굴추적에서 환경변화에 강인한 얼굴 특징에 관한 비교 연구</strong>," 한국멀티미디어학회 추계학술발표대회, 2014.
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          김형일, 이승호, 노용만, "<strong>와일드 환경에서의 얼굴인식 기술 동향</strong>," 한국통신학회지(정보와 통신), 31권, 4호, 88-98 페이지, 2014. [<a href="https://koreascience.kr/article/JAKO201417741960869.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          문정익, 이승호, 김형일, 노용만, "<strong>텍스쳐에 기반하는 강인한 얼굴 검출 방법</strong>," 한국멀티미디어학회 추계학술발표대회, 2013.
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          김형일, 엄원용, 노용만, "<strong>Sparse 표현을 이용한 X선 흡수 영상 개선</strong>," 한국멀티미디어학회논문지, 15권, 10호, 1205-1211 페이지, 2012. [<a href="https://koreascience.kr/article/JAKO201233355899607.pdf" style="text-decoration: none; color: #007bff;"><u>Paper</u></a>]
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          김형일, 엄원용, 노용만, "<strong>Sparse 표현을 이용한 X선 흡수 영상 개선</strong>," 한국멀티미디어학회 춘계학술발표대회, 2012. (우수논문상)
        </td>
      </tr> 
      <tr>
        <td style="width: 100%; vertical-align: top; text-align: justify;">
          김형일, 엄원용, 김대회, 노용만, "<strong>Sparse 표현을 이용한 이중 에너지 X선 흡수 영상 잡음 제거</strong>," 한국정보처리학회 춘계학술발표대회, 2012.
        </td>
      </tr>  
    </table>

  </div>
</section>




      <div id="top-scroller" class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0">
  <a href="#the-top"
    class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top" title="Scroll to top">
    &uarr;
  </a>
</div>
    </main><footer id="site-footer" class="py-10 print:hidden">
  
  
    
  
  <div class="flex items-center justify-between">

    
    
    <p class="text-sm text-neutral-500 dark:text-neutral-400">
      &copy;
      2025
      
    </p>
    

    
    
    
    <p class="text-xs text-neutral-500 dark:text-neutral-400">
      VCL Lab @ School of ECE, Chonnam National University</a>
    </p>
    

  </div>
  <script>
    
    mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
      margin: 24,
      background: 'rgba(0,0,0,0.5)',
      scrollOffset: 0,
    })
    
  </script>
  
  
  <script type="text/javascript" src="/vcl/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js" integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh&#43;sCQ0E53ghYrxgYqw&#43;0GCRyIEpA=="></script>
  
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="https://hikimece.github.io/vcl/"
  style="z-index:500"
>
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>


      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

  </div>
</body>

</html>


